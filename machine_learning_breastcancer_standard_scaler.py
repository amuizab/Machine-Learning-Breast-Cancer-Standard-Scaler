# -*- coding: utf-8 -*-
"""Machine Learning breastcancer standard scaler.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Af_rf0qy5MiCIjXJcs3UyCj0XOij34YI
"""

import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
import numpy as np

from sklearn.preprocessing import LabelEncoder

names = ['id', 'Class', 'f1', 'f2', 'f3', 'f4', 'f5', 'f6', 'f7', 'f8', 'f9', 'f10', 'f11', 'f12', 'f13', 'f14', 'f15', 'f16', 'f17', 'f18', 'f19', 'f20', 'f21', 'f22', 'f23', 'f24', 'f25', 'f26', 'f27', 'f28', 'f29', 'f30']
data = pd.read_csv('https://raw.githubusercontent.com/ilhamsyamsuddin/datasets/main/wdbc.data', names=names)
data

data.isnull().any()

from sklearn.preprocessing import LabelEncoder
encoder = LabelEncoder()
data['Class'] = encoder.fit_transform(data['Class'])

data.pop('id')

data

data.Class.value_counts()

data.corr()

data = data.drop(['f2', 'f5', 'f6', 'f7', 'f9', 'f10', 'f11', 'f12', 'f13', 'f14', 'f15', 'f16', 'f17', 'f18', 'f19', 'f20', 'f22', 'f25', 'f26', 'f27', 'f29', 'f30'], axis = 1)
data

"""SMOTE (datasmote)"""

yy = data.Class
xx = data[['f1', 'f3', 'f4', 'f8', 'f21', 'f23','f24', 'f28']]

xx.shape

yy.shape

from imblearn.over_sampling import SMOTE

su = SMOTE(random_state=42)
xsu, ysu = su.fit_resample(xx, yy)

xsu.shape

ysu.value_counts()

datasmote = pd.concat([ysu,xsu], axis=1)

colors = {1:'r', 0:'b'}
fig, ax = plt.subplots()

for i in range(len(data['f1'])):
    ax.scatter(data['f1'][i], data['f8'][i], color=colors[data['Class'][i]])

ax.set_title('data original')
ax.set_xlabel('fitur1')
ax.set_ylabel('fitur8')

colors = {1:'r', 0:'b'}
fig, ax = plt.subplots()

for i in range(len(datasmote['f1'])):
    ax.scatter(datasmote['f1'][i], datasmote['f8'][i], color=colors[datasmote['Class'][i]])

ax.set_title('data upsmote')
ax.set_xlabel('fitur1')
ax.set_ylabel('fitur8')

"""Check and Remove Outliers"""

plt.boxplot(data.f4)
fig = plt.figure(figsize =(10, 7))
plt.show()

yyy = data.Class
xxx = data[['f1', 'f3', 'f4', 'f8', 'f21', 'f23','f24', 'f28']]
datao = pd.concat([yyy,xxx],axis=1)

def remove_outliers(featr,da):
  x = (da+'o')
  q1 = np.quantile(featr, 0.25)
  q3 = np.quantile(featr, 0.75)

  med = np.median(featr)

  iqr = q3-q1
  upper_bound = q3+(1.5*iqr)
  lower_bound = q1-(1.5*iqr)

  datao[x] = featr[(featr >= lower_bound) & (featr <= upper_bound)]
  datao.pop(da)

  return datao[x]

remove_outliers(datao.f1, ('f1'))
remove_outliers(datao.f3, ('f3'))
remove_outliers(datao.f4, ('f4'))
remove_outliers(datao.f8, ('f8'))

remove_outliers(datao.f21, ('f21'))
remove_outliers(datao.f23, ('f23'))
remove_outliers(datao.f24, ('f24'))
remove_outliers(datao.f28, ('f28'))

datao

"""Data No Outliers Cleaning"""

datao.isnull().any()

datao.shape

datao = datao.dropna()

datao.shape

q1 = np.quantile(data.f4, 0.25)
q3 = np.quantile(data.f4, 0.75)

med = np.median(data.f4)

iqr = q3-q1
upper_bound = q3+(1.5*iqr)
lower_bound = q1-(1.5*iqr)
print(iqr, upper_bound, lower_bound)

outliers = data.f4[(data.f4 <= lower_bound) | (data.f4 >= upper_bound)]
print(outliers)
#print('The following are the outliers in the boxplot:{}'.format(outliers))

data.f4.shape

arr2 = data.f4[(data.f4 >= lower_bound) & (data.f4 <= upper_bound)]
plt.figure(figsize=(10, 7))
plt.boxplot(arr2)
plt.show()

sns.displot(data.f4, kind='hist')

sns.displot(datao.f4o, kind='hist')

"""SMOTE UP No Outliers (dataosmote)"""

yyyy = datao.Class
xxxx = datao[['f1o', 'f3o', 'f4o', 'f8o', 'f21o', 'f23o', 'f24o', 'f28o']]

print(datao.Class.value_counts())
print(yyyy.shape)
print(xxxx.shape)

osu = SMOTE(random_state=42)
xosu, yosu = osu.fit_resample(xxxx, yyyy)
print(xosu.shape,yosu.shape)
dataosmote = pd.concat([yosu,xosu], axis=1)

dataosmote.Class.value_counts()



"""Add Standard Scaler to Features"""

from sklearn.preprocessing import StandardScaler
def standardscal(s,c,cc):
  x = (cc+'sc')
  sc = StandardScaler()
  c[x] = sc.fit_transform(s)
  c.pop(cc)
  return c[x]

standardscal((data[['f1']]), data, ('f1'))
standardscal((data[['f3']]), data, ('f3'))
standardscal((data[['f4']]), data, ('f4'))
standardscal((data[['f8']]), data, ('f8'))

standardscal((data[['f21']]), data, ('f21'))
standardscal((data[['f23']]), data, ('f23'))
standardscal((data[['f24']]), data, ('f24'))
standardscal((data[['f28']]), data, ('f28'))
data

standardscal((datasmote[['f1']]), datasmote, ('f1'))
standardscal((datasmote[['f3']]), datasmote, ('f3'))
standardscal((datasmote[['f4']]), datasmote, ('f4'))
standardscal((datasmote[['f8']]), datasmote, ('f8'))

standardscal((datasmote[['f21']]), datasmote, ('f21'))
standardscal((datasmote[['f23']]), datasmote, ('f23'))
standardscal((datasmote[['f24']]), datasmote, ('f24'))
standardscal((datasmote[['f28']]), datasmote, ('f28'))
datasmote

standardscal((datao[['f1o']]), datao, ('f1o'))
standardscal((datao[['f3o']]), datao, ('f3o'))
standardscal((datao[['f4o']]), datao, ('f4o'))
standardscal((datao[['f8o']]), datao, ('f8o'))

standardscal((datao[['f21o']]), datao, ('f21o'))
standardscal((datao[['f23o']]), datao, ('f23o'))
standardscal((datao[['f24o']]), datao, ('f24o'))
standardscal((datao[['f28o']]), datao, ('f28o'))
datao

standardscal((dataosmote[['f1o']]), dataosmote, ('f1o'))
standardscal((dataosmote[['f3o']]), dataosmote, ('f3o'))
standardscal((dataosmote[['f4o']]), dataosmote, ('f4o'))
standardscal((dataosmote[['f8o']]), dataosmote, ('f8o'))

standardscal((dataosmote[['f21o']]), dataosmote, ('f21o'))
standardscal((dataosmote[['f23o']]), dataosmote, ('f23o'))
standardscal((dataosmote[['f24o']]), dataosmote, ('f24o'))
standardscal((dataosmote[['f28o']]), dataosmote, ('f28o'))
dataosmote

"""# Logistic Regression"""

from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score
from sklearn.metrics import confusion_matrix

log = LogisticRegression()

"""Original Logistic Regression"""

fitur = data.drop(columns='Class').values
label = data['Class']

X_train, X_test, y_train, y_test = train_test_split(fitur, label, test_size=0.3, random_state=2)

log.fit(X_train, y_train)
y_pred = log.predict(X_test)
accuracy_logist_test = accuracy_score(y_test, y_pred)
print(f'Accuracy Score Test Logistic Regression : {accuracy_logist_test*100:.2f} %')

from sklearn.metrics import classification_report
target_names = ['B', 'M']
print(classification_report(y_test, y_pred, target_names=target_names))

conf_logist_test = confusion_matrix(y_test, y_pred)

group_names = ['True Negative', 'False Positive', 'False Negative', 'True Positif']
group_value = ['{0:0.0f}'.format(value) for value in conf_logist_test.ravel()]
group_percentase = ['{:.2f}'.format(value) for value in (conf_logist_test.flatten()/np.sum(conf_logist_test))*100]

labels = [f'{v1}\n{v2}\n{v3} %' for v1, v2, v3 in zip(group_names, group_value, group_percentase)]
labels = np.asarray(labels).reshape(2,2)

plt.figure(figsize=(15,10))
sns.heatmap(conf_logist_test, annot=labels, fmt= '', cmap='Blues', annot_kws={'size':14})

"""No Outliers"""

fituro = datao.drop(columns='Class').values
labelo = datao['Class']

X_traino, X_testo, y_traino, y_testo = train_test_split(fituro, labelo, test_size=0.3, random_state=2)

log.fit(X_traino, y_traino)
y_predo = log.predict(X_testo)
accuracy_logist_testo = accuracy_score(y_testo, y_predo)
print(f'Accuracy Score Test Logistic Regression : {accuracy_logist_testo*100:.2f} %')

from sklearn.metrics import classification_report
target_names = ['B', 'M']
print(classification_report(y_testo, y_predo, target_names=target_names))

conf_logist_test = confusion_matrix(y_testo, y_predo)

group_names = ['True Negative', 'False Positive', 'False Negative', 'True Positif']
group_value = ['{0:0.0f}'.format(value) for value in conf_logist_test.ravel()]
group_percentase = ['{:.2f}'.format(value) for value in (conf_logist_test.flatten()/np.sum(conf_logist_test))*100]

labels = [f'{v1}\n{v2}\n{v3} %' for v1, v2, v3 in zip(group_names, group_value, group_percentase)]
labels = np.asarray(labels).reshape(2,2)

plt.figure(figsize=(15,10))
sns.heatmap(conf_logist_test, annot=labels, fmt= '', cmap='Blues', annot_kws={'size':14})

"""SMOTE Up Logistic Regression"""

fiturs = datasmote.drop(columns='Class').values
labels = datasmote['Class']

X_trains, X_tests, y_trains, y_tests = train_test_split(fiturs, labels, test_size=0.3, random_state=2)

log.fit(X_trains, y_trains)
y_preds = log.predict(X_tests)
accuracy_logist_tests = accuracy_score(y_tests, y_preds)
print(f'Accuracy Score Test Logistic Regression : {accuracy_logist_tests*100:.2f} %')

from sklearn.metrics import classification_report
target_names = ['B', 'M']
print(classification_report(y_tests, y_preds, target_names=target_names))

conf_logist_test = confusion_matrix(y_tests, y_preds)

group_names = ['True Negative', 'False Positive', 'False Negative', 'True Positif']
group_value = ['{0:0.0f}'.format(value) for value in conf_logist_test.ravel()]
group_percentase = ['{:.2f}'.format(value) for value in (conf_logist_test.flatten()/np.sum(conf_logist_test))*100]

labels = [f'{v1}\n{v2}\n{v3} %' for v1, v2, v3 in zip(group_names, group_value, group_percentase)]
labels = np.asarray(labels).reshape(2,2)

plt.figure(figsize=(15,10))
sns.heatmap(conf_logist_test, annot=labels, fmt= '', cmap='Blues', annot_kws={'size':14})

"""No Outliers SMOTE Up"""

fituros = data.drop(columns='Class').values
labelos = data['Class']

X_trainos, X_testos, y_trainos, y_testos = train_test_split(fituros, labelos, test_size=0.3, random_state=2)

log.fit(X_trainos, y_trainos)
y_predos = log.predict(X_testos)
accuracy_logist_testos = accuracy_score(y_testos, y_predos)
print(f'Accuracy Score Test Logistic Regression : {accuracy_logist_testos*100:.2f} %')

from sklearn.metrics import classification_report
target_names = ['B', 'M']
print(classification_report(y_testos, y_predos, target_names=target_names))

conf_logist_test = confusion_matrix(y_testos, y_predos)

group_names = ['True Negative', 'False Positive', 'False Negative', 'True Positif']
group_value = ['{0:0.0f}'.format(value) for value in conf_logist_test.ravel()]
group_percentase = ['{:.2f}'.format(value) for value in (conf_logist_test.flatten()/np.sum(conf_logist_test))*100]

labels = [f'{v1}\n{v2}\n{v3} %' for v1, v2, v3 in zip(group_names, group_value, group_percentase)]
labels = np.asarray(labels).reshape(2,2)

plt.figure(figsize=(15,10))
sns.heatmap(conf_logist_test, annot=labels, fmt= '', cmap='Blues', annot_kws={'size':14})

dataosmote.Class.value_counts()



"""#SVM"""

from sklearn import svm
svm = svm.SVC()

"""Original SVM"""

svm.fit(X_train, y_train)
y_predv = svm.predict(X_test)
accuracy_svm_testv = accuracy_score(y_test, y_predv)
print(f'Accuracy Score Test Logistic Regression : {accuracy_svm_testv*100:.2f} %')

from sklearn.metrics import classification_report
target_names = ['B', 'M']
print(classification_report(y_test, y_predv, target_names=target_names))

import numpy as np
conf_logist_test = confusion_matrix(y_test, y_predv)

group_names = ['True Negative', 'False Positive', 'False Negative', 'True Positif']
group_value = ['{0:0.0f}'.format(value) for value in conf_logist_test.ravel()]
group_percentase = ['{:.2f}'.format(value) for value in (conf_logist_test.flatten()/np.sum(conf_logist_test))*100]

labels = [f'{v1}\n{v2}\n{v3} %' for v1, v2, v3 in zip(group_names, group_value, group_percentase)]
labels = np.asarray(labels).reshape(2,2)

plt.figure(figsize=(15,10))
sns.heatmap(conf_logist_test, annot=labels, fmt= '', cmap='Blues', annot_kws={'size':14})

"""No Outliers"""

svm.fit(X_traino, y_traino)
y_predvo = svm.predict(X_testo)
accuracy_svm_testvo = accuracy_score(y_testo, y_predvo)
print(f'Accuracy Score Test Logistic Regression : {accuracy_svm_testvo*100:.2f} %')

from sklearn.metrics import classification_report
target_names = ['B', 'M']
print(classification_report(y_testo, y_predvo, target_names=target_names))

import numpy as np
conf_logist_test = confusion_matrix(y_testo, y_predvo)

group_names = ['True Negative', 'False Positive', 'False Negative', 'True Positif']
group_value = ['{0:0.0f}'.format(value) for value in conf_logist_test.ravel()]
group_percentase = ['{:.2f}'.format(value) for value in (conf_logist_test.flatten()/np.sum(conf_logist_test))*100]

labels = [f'{v1}\n{v2}\n{v3} %' for v1, v2, v3 in zip(group_names, group_value, group_percentase)]
labels = np.asarray(labels).reshape(2,2)

plt.figure(figsize=(15,10))
sns.heatmap(conf_logist_test, annot=labels, fmt= '', cmap='Blues', annot_kws={'size':14})

"""SMOTE UP SVM"""

svm.fit(X_trains, y_trains)
y_predvs = svm.predict(X_tests)
accuracy_svm_testvs = accuracy_score(y_tests, y_predvs)
print(f'Accuracy Score Test Logistic Regression : {accuracy_svm_testvs*100:.2f} %')

from sklearn.metrics import classification_report
target_names = ['B', 'M']
print(classification_report(y_tests, y_predvs, target_names=target_names))

import numpy as np
conf_logist_test = confusion_matrix(y_tests, y_predvs)

group_names = ['True Negative', 'False Positive', 'False Negative', 'True Positif']
group_value = ['{0:0.0f}'.format(value) for value in conf_logist_test.ravel()]
group_percentase = ['{:.2f}'.format(value) for value in (conf_logist_test.flatten()/np.sum(conf_logist_test))*100]

labels = [f'{v1}\n{v2}\n{v3} %' for v1, v2, v3 in zip(group_names, group_value, group_percentase)]
labels = np.asarray(labels).reshape(2,2)

plt.figure(figsize=(15,10))
sns.heatmap(conf_logist_test, annot=labels, fmt= '', cmap='Blues', annot_kws={'size':14})

"""No Outliers SMOTE UP"""

svm.fit(X_trainos, y_trainos)
y_predvos = svm.predict(X_testos)
accuracy_svm_testvos = accuracy_score(y_testos, y_predvos)
print(f'Accuracy Score Test Logistic Regression : {accuracy_svm_testvos*100:.2f} %')

from sklearn.metrics import classification_report
target_names = ['B', 'M']
print(classification_report(y_testos, y_predvos, target_names=target_names))

import numpy as np
conf_logist_test = confusion_matrix(y_testos, y_predvos)

group_names = ['True Negative', 'False Positive', 'False Negative', 'True Positif']
group_value = ['{0:0.0f}'.format(value) for value in conf_logist_test.ravel()]
group_percentase = ['{:.2f}'.format(value) for value in (conf_logist_test.flatten()/np.sum(conf_logist_test))*100]

labels = [f'{v1}\n{v2}\n{v3} %' for v1, v2, v3 in zip(group_names, group_value, group_percentase)]
labels = np.asarray(labels).reshape(2,2)

plt.figure(figsize=(15,10))
sns.heatmap(conf_logist_test, annot=labels, fmt= '', cmap='Blues', annot_kws={'size':14})

